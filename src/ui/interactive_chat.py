"""
Interactive Chat Interface for RAG-based conversations
"""

import streamlit as st
from typing import List, Dict, Any, Optional
import json
from datetime import datetime
import pandas as pd
import plotly.graph_objects as go
from pathlib import Path

from src.rag.enhanced_rag_engine import EnhancedRAGEngine, RAGQuery, RAGResponse

class InteractiveChatInterface:
    """ëŒ€í™”í˜• ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.initialize_session_state()
        
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        if 'rag_engine' not in st.session_state:
            st.session_state.rag_engine = None
            
        if 'chat_settings' not in st.session_state:
            st.session_state.chat_settings = {
                'context_window': 5,
                'min_similarity': 0.5,
                'rerank': True,
                'show_sources': True,
                'show_confidence': True
            }
    
    def render(self):
        """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        st.header("ğŸ¤– AI Assistant Chat")
        
        # RAG ì—”ì§„ í™•ì¸
        if st.session_state.rag_engine is None:
            st.warning("âš ï¸ Please setup embeddings and initialize the system first.")
            return
        
        # ì±„íŒ… ì„¤ì • ì‚¬ì´ë“œë°”
        self._render_chat_settings()
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        self._render_chat_history()
        
        # ì…ë ¥ ì¸í„°í˜ì´ìŠ¤
        self._render_input_interface()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
        self._render_metrics()
    
    def _render_chat_settings(self):
        """ì±„íŒ… ì„¤ì • ë Œë”ë§"""
        with st.sidebar.expander("ğŸ’¬ Chat Settings", expanded=True):
            st.session_state.chat_settings['context_window'] = st.slider(
                "Context Window",
                min_value=1,
                max_value=20,
                value=st.session_state.chat_settings['context_window'],
                help="Number of sources to retrieve"
            )
            
            st.session_state.chat_settings['min_similarity'] = st.slider(
                "Minimum Similarity",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.chat_settings['min_similarity'],
                step=0.1,
                help="Minimum similarity score for retrieved documents"
            )
            
            st.session_state.chat_settings['rerank'] = st.checkbox(
                "Enable Reranking",
                value=st.session_state.chat_settings['rerank'],
                help="Rerank retrieved documents for better relevance"
            )
            
            st.session_state.chat_settings['show_sources'] = st.checkbox(
                "Show Sources",
                value=st.session_state.chat_settings['show_sources'],
                help="Display source documents with answers"
            )
            
            st.session_state.chat_settings['show_confidence'] = st.checkbox(
                "Show Confidence Score",
                value=st.session_state.chat_settings['show_confidence'],
                help="Display confidence score for answers"
            )
            
            if st.button("Clear Chat History", type="secondary"):
                st.session_state.chat_history = []
                st.rerun()
    
    def _render_chat_history(self):
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë Œë”ë§"""
        chat_container = st.container()
        
        with chat_container:
            for i, message in enumerate(st.session_state.chat_history):
                if message['role'] == 'user':
                    with st.chat_message("user"):
                        st.write(message['content'])
                else:
                    with st.chat_message("assistant"):
                        # ë‹µë³€ í‘œì‹œ
                        st.write(message['content'])
                        
                        # ì‹ ë¢°ë„ í‘œì‹œ
                        if st.session_state.chat_settings['show_confidence'] and 'confidence' in message:
                            confidence = message['confidence']
                            color = self._get_confidence_color(confidence)
                            st.markdown(
                                f"<small style='color: {color}'>Confidence: {confidence:.2%}</small>",
                                unsafe_allow_html=True
                            )
                        
                        # ì†ŒìŠ¤ í‘œì‹œ
                        if st.session_state.chat_settings['show_sources'] and 'sources' in message:
                            self._render_sources(message['sources'], f"sources_{i}")
    
    def _render_input_interface(self):
        """ì…ë ¥ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        # ì…ë ¥ í¼
        with st.form(key="chat_form", clear_on_submit=True):
            col1, col2 = st.columns([5, 1])
            
            with col1:
                user_input = st.text_input(
                    "Ask a question...",
                    placeholder="Type your question here",
                    label_visibility="collapsed"
                )
            
            with col2:
                submit_button = st.form_submit_button("Send", use_container_width=True)
        
        # ì§ˆë¬¸ ì œì•ˆ
        st.markdown("**Suggested questions:**")
        col1, col2, col3 = st.columns(3)
        
        suggestions = [
            "What is UVM?",
            "How to debug UVM errors?",
            "Explain sequence items",
            "What are virtual interfaces?",
            "How to use scoreboard?",
            "Explain factory pattern"
        ]
        
        for i, suggestion in enumerate(suggestions):
            col = [col1, col2, col3][i % 3]
            with col:
                if st.button(suggestion, key=f"suggestion_{i}"):
                    self._process_query(suggestion)
                    st.rerun()
        
        # í¼ ì œì¶œ ì²˜ë¦¬
        if submit_button and user_input:
            self._process_query(user_input)
            st.rerun()
    
    def _process_query(self, query: str):
        """ì¿¼ë¦¬ ì²˜ë¦¬"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({
            'role': 'user',
            'content': query,
            'timestamp': datetime.now().isoformat()
        })
        
        # RAG ì¿¼ë¦¬ ìƒì„±
        rag_query = RAGQuery(
            query=query,
            context_window=st.session_state.chat_settings['context_window'],
            rerank=st.session_state.chat_settings['rerank'],
            min_similarity=st.session_state.chat_settings['min_similarity'],
            include_metadata=True
        )
        
        # RAG ì—”ì§„ í˜¸ì¶œ
        with st.spinner("Thinking..."):
            response = st.session_state.rag_engine.query(rag_query)
        
        # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({
            'role': 'assistant',
            'content': response.answer,
            'sources': response.sources,
            'confidence': response.confidence,
            'reasoning': response.reasoning,
            'metadata': response.metadata,
            'timestamp': datetime.now().isoformat()
        })
    
    def _render_sources(self, sources: List[Dict[str, Any]], key_prefix: str):
        """ì†ŒìŠ¤ ë¬¸ì„œ ë Œë”ë§"""
        if not sources:
            return
        
        with st.expander(f"ğŸ“š Sources ({len(sources)})", expanded=False):
            for i, source in enumerate(sources):
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                    metadata = source.get('metadata', {})
                    source_info = []
                    
                    if 'file_name' in metadata:
                        source_info.append(f"ğŸ“„ {metadata['file_name']}")
                    if 'page' in metadata:
                        source_info.append(f"Page {metadata['page']}")
                    if 'section' in metadata:
                        source_info.append(f"Section: {metadata['section']}")
                    
                    if source_info:
                        st.markdown(f"**{' | '.join(source_info)}**")
                    
                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                    content_preview = source['content'][:200] + "..." if len(source['content']) > 200 else source['content']
                    st.text(content_preview)
                
                with col2:
                    # ê´€ë ¨ì„± ì ìˆ˜
                    score = source.get('score', 0)
                    st.metric("Score", f"{score:.3f}")
                
                if i < len(sources) - 1:
                    st.divider()
    
    def _render_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë Œë”ë§"""
        if st.session_state.rag_engine is None:
            return
        
        metrics = st.session_state.rag_engine.get_metrics()
        
        with st.expander("ğŸ“Š Performance Metrics", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Total Queries",
                    metrics['queries_processed']
                )
            
            with col2:
                st.metric(
                    "Avg Response Time",
                    f"{metrics['average_response_time']:.2f}s"
                )
            
            with col3:
                st.metric(
                    "Avg Confidence",
                    f"{metrics['average_confidence']:.2%}"
                )
            
            with col4:
                st.metric(
                    "Cache Hits",
                    metrics['cache_hits']
                )
            
            # ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸
            if st.session_state.chat_history:
                self._render_query_history_chart()
    
    def _render_query_history_chart(self):
        """ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸ ë Œë”ë§"""
        # ë°ì´í„° ì¤€ë¹„
        data = []
        for msg in st.session_state.chat_history:
            if msg['role'] == 'assistant' and 'confidence' in msg:
                data.append({
                    'timestamp': pd.to_datetime(msg['timestamp']),
                    'confidence': msg['confidence'],
                    'response_time': msg.get('metadata', {}).get('query_time', 0)
                })
        
        if not data:
            return
        
        df = pd.DataFrame(data)
        
        # ì‹ ë¢°ë„ ì°¨íŠ¸
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=df['timestamp'],
            y=df['confidence'],
            mode='lines+markers',
            name='Confidence',
            line=dict(color='blue', width=2),
            marker=dict(size=8)
        ))
        
        fig.update_layout(
            title="Query Confidence Over Time",
            xaxis_title="Time",
            yaxis_title="Confidence Score",
            yaxis_range=[0, 1],
            height=300
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _get_confidence_color(self, confidence: float) -> str:
        """ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
        if confidence >= 0.8:
            return "#27ae60"  # Green
        elif confidence >= 0.6:
            return "#f39c12"  # Orange
        else:
            return "#e74c3c"  # Red
    
    def export_chat_history(self) -> str:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°"""
        export_data = {
            'exported_at': datetime.now().isoformat(),
            'settings': st.session_state.chat_settings,
            'history': st.session_state.chat_history
        }
        
        return json.dumps(export_data, indent=2, ensure_ascii=False)
    
    def import_chat_history(self, data: str):
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
        try:
            imported_data = json.loads(data)
            st.session_state.chat_history = imported_data.get('history', [])
            st.session_state.chat_settings.update(imported_data.get('settings', {}))
            return True
        except Exception as e:
            st.error(f"Failed to import chat history: {str(e)}")
            return False 