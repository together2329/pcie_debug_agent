#!/bin/bash

echo "ğŸš€ DeepSeek Q4_1 vs Llama 3.2 3B Setup and Test Script"
echo "========================================================="
echo ""

# Check system info
echo "ğŸ“± System Information:"
system_profiler SPHardwareDataType | grep "Model Name\|Memory\|Chip"
echo ""

# Check if Ollama is installed
echo "ğŸ” Checking Ollama installation..."
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is installed: $(ollama --version)"
else
    echo "âŒ Ollama not found. Installing..."
    curl -fsSL https://ollama.com/install.sh | sh
    echo "âœ… Ollama installed"
fi
echo ""

# Check current Ollama models
echo "ğŸ“‹ Current Ollama models:"
ollama list
echo ""

# Check if DeepSeek model is available
echo "ğŸ” Checking DeepSeek Q4_1 model..."
if ollama list | grep -q "deepseek-r1:8b-0528-qwen3-q4_1"; then
    echo "âœ… DeepSeek Q4_1 model is already available"
else
    echo "ğŸ“¥ DeepSeek Q4_1 model not found. Downloading..."
    echo "âš ï¸  This will download ~5.2 GB. Continue? (y/n)"
    read -r response
    if [[ "$response" =~ ^[Yy]$ ]]; then
        echo "ğŸ”„ Downloading DeepSeek Q4_1 model..."
        ollama pull deepseek-r1:8b-0528-qwen3-q4_1
        echo "âœ… DeepSeek Q4_1 model downloaded"
    else
        echo "â­ï¸ Skipping DeepSeek download"
    fi
fi
echo ""

# Check Python dependencies
echo "ğŸ” Checking Python dependencies..."
python3 -c "import psutil; print('âœ… psutil available')" 2>/dev/null || echo "âŒ psutil not available - install with: pip install psutil"

# Check if local Llama is available
echo "ğŸ” Checking local Llama setup..."
cd /Users/brian/Desktop/Project/pcie_debug_agent
python3 -c "
try:
    from src.models.local_llm_provider import LocalLLMProvider
    provider = LocalLLMProvider()
    if provider.is_available():
        print('âœ… Llama 3.2 3B model is available')
    else:
        print('âš ï¸ Llama 3.2 3B model not found - will auto-download on first use')
except Exception as e:
    print(f'âŒ Llama setup issue: {e}')
"
echo ""

# Quick test DeepSeek
echo "ğŸ§ª Quick DeepSeek test..."
if ollama list | grep -q "deepseek-r1:8b-0528-qwen3-q4_1"; then
    echo "Testing DeepSeek with a simple query..."
    echo "What is PCIe?" | ollama run deepseek-r1:8b-0528-qwen3-q4_1 | head -3
    echo "âœ… DeepSeek test completed"
else
    echo "â­ï¸ Skipping DeepSeek test - model not available"
fi
echo ""

# Run the comprehensive comparison
echo "ğŸ”¬ Ready to run comprehensive comparison?"
echo "This will test both models on 6 PCIe debugging scenarios"
echo "Continue? (y/n)"
read -r response
if [[ "$response" =~ ^[Yy]$ ]]; then
    echo "ğŸš€ Running comprehensive comparison..."
    python3 src/simulators/deepseek_vs_llama_test.py
else
    echo "â­ï¸ Skipping comprehensive test"
    echo ""
    echo "To run manually later:"
    echo "  cd /Users/brian/Desktop/Project/pcie_debug_agent"
    echo "  python3 src/simulators/deepseek_vs_llama_test.py"
fi

echo ""
echo "ğŸ‰ Setup complete!"
echo ""
echo "ğŸ“‹ What's been set up:"
echo "  âœ… Ollama installation verified"
echo "  âœ… DeepSeek Q4_1 model available (if downloaded)"
echo "  âœ… Comprehensive test script ready"
echo ""
echo "ğŸš€ Next steps:"
echo "  1. Run: python3 src/simulators/deepseek_vs_llama_test.py"
echo "  2. Compare the detailed results"
echo "  3. Choose the best model for your PCIe debugging needs"